{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dfs = [pd.read_csv(f'output/feat_df_{str(i)}').drop('Unnamed: 0', axis=1) for i in range(6)]\n",
    "combined_feats = pd.read_csv('output/combined_feats').drop('Unnamed: 0', axis=1)\n",
    "train_scores = pd.read_csv('input/train_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSQE: validation set for pattern info: 0.82\n",
      "MSQE: validation set for n-gram tdidf: 0.703\n",
      "MSQE: validation set for iki info: 0.725\n",
      "MSQE: validation set for agg info: 0.657\n",
      "MSQE: validation set for other count info: 0.726\n",
      "MSQE: validation set for gap info: 0.685\n"
     ]
    }
   ],
   "source": [
    "X, y = combined_feats, train_scores['score']\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=rs)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=.25, random_state=rs)\n",
    "df_names = ['pattern info', 'n-gram tdidf', 'iki info', 'agg info', 'other count info', 'gap info']\n",
    "y_trains = []\n",
    "y_valids = []\n",
    "for i, df in enumerate(feature_dfs):\n",
    "    model = GradientBoostingRegressor()\n",
    "    model.fit(X_train[df.columns], y_train)\n",
    "    y_predict_train = model.predict(X_train[df.columns])\n",
    "    y_predict_valid = model.predict(X_valid[df.columns])\n",
    "    print(f'MSQE: validation set for {df_names[i]}: {round(mean_squared_error(y_valid, y_predict_valid, squared=False), 3)}')\n",
    "    y_trains.append(y_predict_train)\n",
    "    y_valids.append(y_predict_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSQE: training set, 0.467\n",
      "MSQE: validation set for gap info, 0.626\n"
     ]
    }
   ],
   "source": [
    "weights = [.1, .1, .1, .35, .1, .25]\n",
    "y_train_combined, y_valids_combined = y_trains[0] * weights[0], y_valids[0] * weights[0]\n",
    "for i in range(1, len(weights)):\n",
    "    y_train_combined += y_trains[i] * weights[i]\n",
    "    y_valids_combined += y_valids[i] * weights[i]\n",
    "print(f'MSQE: training set, {round(mean_squared_error(y_train_combined, y_train, squared=False), 3)}')\n",
    "print(f'MSQE: validation set for {df_names[i]}, {round(mean_squared_error(y_valids_combined, y_valid, squared=False), 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "import tensorflow as tf\n",
    "\n",
    "rs=0\n",
    "X, y = combined_feats, train_scores['score']\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=rs)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=.25, random_state=rs)\n",
    "\n",
    "def print_results(model_name, gs):\n",
    "    print(f'Best Score for {model_name}: {round(-gs.best_score_, 3)}, Best Params: {gs.best_params_}')\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        'name': 'Ridge',\n",
    "        'model': Ridge,\n",
    "        'params': {\n",
    "            'alpha': [0, .1, 1, 10],\n",
    "            'fit_intercept'    : [True, False]\n",
    "        },\n",
    "        'preprocess': lambda X: X\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ridge with Polynomial Features',\n",
    "        'model': Ridge,\n",
    "        'params': {\n",
    "            'alpha': [0, .1, 1, 10],\n",
    "            'fit_intercept': [True, False]\n",
    "        },\n",
    "        'preprocess': lambda X: PolynomialFeatures(degree=2).fit_transform(StandardScaler().fit_transform(X))\n",
    "    },\n",
    "        {\n",
    "        'name': 'Lasso',\n",
    "        'model': Lasso,\n",
    "        'params': {\n",
    "            'alpha': [0, .01, .1, .3],\n",
    "            'fit_intercept'    : [True, False]\n",
    "        },\n",
    "        'preprocess': lambda X: X\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lasso with Polynomial Features',\n",
    "        'model': Lasso,\n",
    "        'params': {\n",
    "            'alpha': [0, .01, .1, .3],\n",
    "            'fit_intercept': [True, False]\n",
    "        },\n",
    "        'preprocess': lambda X: PolynomialFeatures(degree=2).fit_transform(StandardScaler().fit_transform(X))\n",
    "    },\n",
    "    {\n",
    "        'name': 'KNN',\n",
    "        'model': KNeighborsRegressor,\n",
    "        'params': {\n",
    "            'n_neighbors' : [1, 2, 3, 5, 10, 20, 50, 100]\n",
    "        },\n",
    "        'preprocess': lambda X: StandardScaler().fit_transform(X)\n",
    "    },\n",
    "    {\n",
    "        'name': 'SVR',\n",
    "        'model': SVR,\n",
    "        'params': {\n",
    "            'kernel' : ['linear', 'poly', 'rbf'],\n",
    "            'C' : [.01, .1, 1],\n",
    "            'degree' : [1, 2],\n",
    "            'gamma' : [.01, .1, .5]\n",
    "        },\n",
    "        'preprocess': lambda X: StandardScaler().fit_transform(X)\n",
    "    },\n",
    "    {\n",
    "        'name': 'GBR',\n",
    "        'model': GradientBoostingRegressor,\n",
    "        'params': {\n",
    "            'n_estimators': [10, 50, 100, 200],\n",
    "            'subsample': [.5, .65, .8, .9, 1],\n",
    "            'max_depth': [2, 3, 8]\n",
    "        },\n",
    "        'preprocess': lambda X: X\n",
    "    },\n",
    "    {\n",
    "        'name': 'LGBM',\n",
    "        'model': LGBMRegressor,\n",
    "        'params': {\n",
    "            'subsample': [.5, .65, .8, .9, 1],\n",
    "            'learning_rate': [0.1, 0.03, 0.003],\n",
    "            'max_depth': [2, 3, 8],\n",
    "            'n_estimators': [10, 50, 100, 200],\n",
    "            'num_leaves': [131072]\n",
    "        },\n",
    "        'preprocess': lambda X: X.set_axis([str(i) for i in range(X.shape[1])], axis=1)\n",
    "    },\n",
    "    {\n",
    "        'name': 'XGB',\n",
    "        'model': XGBRegressor,\n",
    "        'params': {\n",
    "            'subsample': [.5, .65, .8, .9, 1],\n",
    "            'learning_rate': [0.1, 0.03, 0.003],\n",
    "            'max_depth': [2, 3, 8],\n",
    "            'n_estimators': [10, 50, 100, 200],\n",
    "        },\n",
    "        'preprocess': lambda X: X\n",
    "    },\n",
    "]\n",
    "\n",
    "def run_tests(cols):\n",
    "    results = {}\n",
    "    for model in models:\n",
    "        gs = GridSearchCV(estimator=model['model'](), param_grid=model['params'], \n",
    "            scoring='neg_root_mean_squared_error', cv=4)\n",
    "        gs.fit(model['preprocess'](X_train[cols]), y_train)\n",
    "        print_results(model['name'], gs)\n",
    " \n",
    "        # print_results('Ridge Model', gs)\n",
    "        tuned_model = model['model'](**gs.best_params_)\n",
    "        tuned_model.fit(model['preprocess'](X_train[cols]), y_train)\n",
    "        y_pred = tuned_model.predict(model['preprocess'](X_valid[cols]))\n",
    "        results[model['name']] = {\n",
    "            'score': round(-gs.best_score_, 3), \n",
    "            'y_pred': y_pred,\n",
    "            'model': tuned_model\n",
    "        }\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Normalization(input_shape=[len(cols)]),\n",
    "        tf.keras.layers.Dense(300, activation='relu'),\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\n",
    "        tf.keras.layers.Dense(20, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='mse', optimizer='sgd', metrics=['RootMeanSquaredError'])\n",
    "    model.fit(X_train[cols], y_train, epochs=30, validation_data=(X_valid[cols], y_valid))\n",
    "    results['NN'] = {\n",
    "        'score': round(model.evaluate(X_valid[cols], y_valid)[1], 3),\n",
    "        'y_pred': model.predict(X_valid[cols]),\n",
    "        'model': model\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find ensemble model for pattern info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for Ridge: 0.933, Best Params: {'alpha': 10, 'fit_intercept': True}\n",
      "Best Score for Ridge with Polynomial Features: 1.026, Best Params: {'alpha': 10, 'fit_intercept': True}\n",
      "Best Score for Lasso: 0.929, Best Params: {'alpha': 0.01, 'fit_intercept': True}\n",
      "Best Score for Lasso with Polynomial Features: 0.934, Best Params: {'alpha': 0.01, 'fit_intercept': True}\n",
      "Best Score for KNN: 0.903, Best Params: {'n_neighbors': 50}\n",
      "Best Score for SVR: 0.897, Best Params: {'C': 1, 'degree': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best Score for GBR: 0.875, Best Params: {'max_depth': 2, 'n_estimators': 50, 'subsample': 0.65}\n",
      "Best Score for LGBM: 0.873, Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'n_estimators': 200, 'num_leaves': 131072, 'subsample': 0.5}\n",
      "Best Score for XGB: 0.874, Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.65}\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 1s 9ms/step - loss: 2.6120 - root_mean_squared_error: 1.6162 - val_loss: 1.1708 - val_root_mean_squared_error: 1.0820\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.1473 - root_mean_squared_error: 1.0711 - val_loss: 0.8432 - val_root_mean_squared_error: 0.9183\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9857 - root_mean_squared_error: 0.9928 - val_loss: 1.4170 - val_root_mean_squared_error: 1.1904\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9158 - root_mean_squared_error: 0.9570 - val_loss: 0.7956 - val_root_mean_squared_error: 0.8920\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.8534 - root_mean_squared_error: 0.9238 - val_loss: 1.2925 - val_root_mean_squared_error: 1.1369\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.8533 - root_mean_squared_error: 0.9238 - val_loss: 0.7777 - val_root_mean_squared_error: 0.8819\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.8113 - root_mean_squared_error: 0.9007 - val_loss: 0.7555 - val_root_mean_squared_error: 0.8692\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7772 - root_mean_squared_error: 0.8816 - val_loss: 0.8077 - val_root_mean_squared_error: 0.8987\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.8119 - root_mean_squared_error: 0.9011 - val_loss: 0.8785 - val_root_mean_squared_error: 0.9373\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7685 - root_mean_squared_error: 0.8766 - val_loss: 0.7371 - val_root_mean_squared_error: 0.8585\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7903 - root_mean_squared_error: 0.8890 - val_loss: 0.8948 - val_root_mean_squared_error: 0.9460\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7796 - root_mean_squared_error: 0.8829 - val_loss: 0.7955 - val_root_mean_squared_error: 0.8919\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7641 - root_mean_squared_error: 0.8741 - val_loss: 0.9334 - val_root_mean_squared_error: 0.9661\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7532 - root_mean_squared_error: 0.8679 - val_loss: 0.7442 - val_root_mean_squared_error: 0.8627\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7471 - root_mean_squared_error: 0.8644 - val_loss: 0.8816 - val_root_mean_squared_error: 0.9389\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7508 - root_mean_squared_error: 0.8665 - val_loss: 0.7175 - val_root_mean_squared_error: 0.8470\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7480 - root_mean_squared_error: 0.8649 - val_loss: 0.7153 - val_root_mean_squared_error: 0.8458\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7363 - root_mean_squared_error: 0.8581 - val_loss: 0.7385 - val_root_mean_squared_error: 0.8594\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7243 - root_mean_squared_error: 0.8510 - val_loss: 0.7395 - val_root_mean_squared_error: 0.8599\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7296 - root_mean_squared_error: 0.8541 - val_loss: 0.7539 - val_root_mean_squared_error: 0.8683\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7265 - root_mean_squared_error: 0.8524 - val_loss: 0.7128 - val_root_mean_squared_error: 0.8443\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7235 - root_mean_squared_error: 0.8506 - val_loss: 0.7765 - val_root_mean_squared_error: 0.8812\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7262 - root_mean_squared_error: 0.8522 - val_loss: 0.7269 - val_root_mean_squared_error: 0.8526\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7193 - root_mean_squared_error: 0.8481 - val_loss: 0.7463 - val_root_mean_squared_error: 0.8639\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7201 - root_mean_squared_error: 0.8486 - val_loss: 0.7289 - val_root_mean_squared_error: 0.8538\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7134 - root_mean_squared_error: 0.8447 - val_loss: 0.7208 - val_root_mean_squared_error: 0.8490\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7023 - root_mean_squared_error: 0.8381 - val_loss: 0.7148 - val_root_mean_squared_error: 0.8455\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7063 - root_mean_squared_error: 0.8404 - val_loss: 0.7784 - val_root_mean_squared_error: 0.8823\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7016 - root_mean_squared_error: 0.8376 - val_loss: 0.7551 - val_root_mean_squared_error: 0.8690\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7012 - root_mean_squared_error: 0.8374 - val_loss: 0.8018 - val_root_mean_squared_error: 0.8954\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8018 - root_mean_squared_error: 0.8954\n",
      "16/16 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "results_pattern = run_tests(feature_dfs[0].columns)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step\n",
      "Validation score for model: Ridge -- 0.923\n",
      "Validation score for model: Ridge with Polynomial Features -- 1.367\n",
      "Validation score for model: Lasso -- 0.914\n",
      "Validation score for model: Lasso with Polynomial Features -- 0.806\n",
      "Validation score for model: KNN -- 0.766\n",
      "Validation score for model: SVR -- 0.749\n",
      "Validation score for model: GBR -- 0.743\n",
      "Validation score for model: LGBM -- 0.745\n",
      "Validation score for model: XGB -- 0.74\n",
      "Validation score for model: NN -- 0.894\n",
      "Weighted ensemble of models for validation set: 0.74\n"
     ]
    }
   ],
   "source": [
    "changable_rs = 0\n",
    "to_print = []\n",
    "y_valid_preds_patterns = []\n",
    "X, y = combined_feats, train_scores['score']\n",
    "X, X_valid, y, y_valid = train_test_split(X, y, test_size=.2, random_state=changable_rs)\n",
    "for model in models + [{'name': 'NN', 'preprocess': lambda X: X}]:\n",
    "    tuned_model = results_pattern[model['name']]['model']\n",
    "    y_pred = tuned_model.predict(model['preprocess'](X_valid[feature_dfs[0].columns]))\n",
    "    y_valid_preds_patterns.append({\n",
    "        'model': model['name'], \n",
    "        'features': 'patterns', \n",
    "        'y_valid_pred': y_pred if model['name'] != 'NN' else y_pred[:,0], \n",
    "        'score': mean_squared_error(y_pred, y_valid)})\n",
    "\n",
    "weights = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "y_valid_pred_pattern = []\n",
    "for i in range(len(y_valid_preds_patterns)):\n",
    "    sc = round(mean_squared_error(y_valid, y_valid_preds_patterns[i]['y_valid_pred']), 3)\n",
    "    print(f'Validation score for model: {y_valid_preds_patterns[i][\"model\"]} -- {sc}')\n",
    "for i in range(len(y_valid_preds_patterns)):\n",
    "    vect = y_valid_preds_patterns[i]['y_valid_pred'] * weights[i]\n",
    "    if i == 0:\n",
    "        y_valid_pred_pattern = vect\n",
    "    else:\n",
    "        y_valid_pred_pattern = y_valid_pred_pattern + vect\n",
    "sc = round(mean_squared_error(y_valid, y_valid_pred_pattern), 3)\n",
    "print(f'Weighted ensemble of models for validation set: {sc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find ensemble info for n-gram tdidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for Ridge: 0.996, Best Params: {'alpha': 0, 'fit_intercept': True}\n",
      "Best Score for Ridge with Polynomial Features: 1.476, Best Params: {'alpha': 10, 'fit_intercept': True}\n",
      "Best Score for Lasso: 0.996, Best Params: {'alpha': 0, 'fit_intercept': True}\n",
      "Best Score for Lasso with Polynomial Features: 0.876, Best Params: {'alpha': 0.01, 'fit_intercept': False}\n",
      "Best Score for KNN: 1.095, Best Params: {'n_neighbors': 100}\n",
      "Best Score for SVR: 0.76, Best Params: {'C': 1, 'degree': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best Score for GBR: 0.711, Best Params: {'max_depth': 2, 'n_estimators': 100, 'subsample': 1}\n",
      "Best Score for LGBM: 0.71, Best Params: {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 200, 'num_leaves': 131072, 'subsample': 0.5}\n",
      "Best Score for XGB: 0.712, Best Params: {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 1s 9ms/step - loss: 2.9456 - root_mean_squared_error: 1.7163 - val_loss: 1.0228 - val_root_mean_squared_error: 1.0113\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0932 - root_mean_squared_error: 1.0455 - val_loss: 1.0233 - val_root_mean_squared_error: 1.0116\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0991 - root_mean_squared_error: 1.0484 - val_loss: 0.9791 - val_root_mean_squared_error: 0.9895\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0966 - root_mean_squared_error: 1.0472 - val_loss: 0.9814 - val_root_mean_squared_error: 0.9906\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.1010 - root_mean_squared_error: 1.0493 - val_loss: 0.9753 - val_root_mean_squared_error: 0.9876\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0945 - root_mean_squared_error: 1.0462 - val_loss: 0.9872 - val_root_mean_squared_error: 0.9936\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0915 - root_mean_squared_error: 1.0448 - val_loss: 1.0056 - val_root_mean_squared_error: 1.0028\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0929 - root_mean_squared_error: 1.0454 - val_loss: 0.9813 - val_root_mean_squared_error: 0.9906\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0933 - root_mean_squared_error: 1.0456 - val_loss: 0.9752 - val_root_mean_squared_error: 0.9875\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0962 - root_mean_squared_error: 1.0470 - val_loss: 0.9767 - val_root_mean_squared_error: 0.9883\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0967 - root_mean_squared_error: 1.0473 - val_loss: 0.9770 - val_root_mean_squared_error: 0.9884\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0931 - root_mean_squared_error: 1.0455 - val_loss: 0.9826 - val_root_mean_squared_error: 0.9912\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0955 - root_mean_squared_error: 1.0467 - val_loss: 0.9734 - val_root_mean_squared_error: 0.9866\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0924 - root_mean_squared_error: 1.0452 - val_loss: 0.9892 - val_root_mean_squared_error: 0.9946\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0940 - root_mean_squared_error: 1.0460 - val_loss: 0.9746 - val_root_mean_squared_error: 0.9872\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0943 - root_mean_squared_error: 1.0461 - val_loss: 0.9800 - val_root_mean_squared_error: 0.9899\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0904 - root_mean_squared_error: 1.0442 - val_loss: 0.9745 - val_root_mean_squared_error: 0.9872\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0883 - root_mean_squared_error: 1.0432 - val_loss: 1.0582 - val_root_mean_squared_error: 1.0287\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0946 - root_mean_squared_error: 1.0462 - val_loss: 1.0686 - val_root_mean_squared_error: 1.0337\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0958 - root_mean_squared_error: 1.0468 - val_loss: 1.0211 - val_root_mean_squared_error: 1.0105\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0916 - root_mean_squared_error: 1.0448 - val_loss: 0.9803 - val_root_mean_squared_error: 0.9901\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0887 - root_mean_squared_error: 1.0434 - val_loss: 0.9723 - val_root_mean_squared_error: 0.9860\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0963 - root_mean_squared_error: 1.0470 - val_loss: 0.9736 - val_root_mean_squared_error: 0.9867\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0906 - root_mean_squared_error: 1.0443 - val_loss: 1.0023 - val_root_mean_squared_error: 1.0012\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 1.0900 - root_mean_squared_error: 1.0440 - val_loss: 1.0400 - val_root_mean_squared_error: 1.0198\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.1009 - root_mean_squared_error: 1.0492 - val_loss: 0.9767 - val_root_mean_squared_error: 0.9883\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0905 - root_mean_squared_error: 1.0443 - val_loss: 0.9728 - val_root_mean_squared_error: 0.9863\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0976 - root_mean_squared_error: 1.0477 - val_loss: 0.9882 - val_root_mean_squared_error: 0.9941\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0972 - root_mean_squared_error: 1.0475 - val_loss: 0.9870 - val_root_mean_squared_error: 0.9935\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0882 - root_mean_squared_error: 1.0432 - val_loss: 0.9791 - val_root_mean_squared_error: 0.9895\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9791 - root_mean_squared_error: 0.9895\n",
      "16/16 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "results_ngram = run_tests(feature_dfs[1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step\n",
      "Validation score for model: Ridge -- 0.951\n",
      "Validation score for model: Ridge with Polynomial Features -- 1.22\n",
      "Validation score for model: Lasso -- 0.951\n",
      "Validation score for model: Lasso with Polynomial Features -- 0.602\n",
      "Validation score for model: KNN -- 1.069\n",
      "Validation score for model: SVR -- 0.523\n",
      "Validation score for model: GBR -- 0.447\n",
      "Validation score for model: LGBM -- 0.432\n",
      "Validation score for model: XGB -- 0.439\n",
      "Validation score for model: NN -- 0.979\n",
      "Weighted ensemble of models for validation set: 0.432\n"
     ]
    }
   ],
   "source": [
    "changable_rs = 0\n",
    "X, y = combined_feats, train_scores['score']\n",
    "X, X_valid, y, y_valid = train_test_split(X, y, test_size=.2, random_state=changable_rs)\n",
    "\n",
    "y_valid_preds_ngrams = []\n",
    "for model in models + [{'name': 'NN', 'preprocess': lambda X: X}]:\n",
    "    tuned_model = results_ngram[model['name']]['model']\n",
    "    y_pred = tuned_model.predict(model['preprocess'](X_valid[feature_dfs[1].columns]))\n",
    "    y_valid_preds_ngrams.append({\n",
    "        'model': model['name'], \n",
    "        'features': 'patterns', \n",
    "        'y_valid_pred': y_pred if model['name'] != 'NN' else y_pred[:,0], \n",
    "        'score': mean_squared_error(y_pred, y_valid)})\n",
    "\n",
    "weights = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "y_valid_pred_ngram = []\n",
    "for i in range(len(y_valid_preds_ngrams)):\n",
    "    sc = round(mean_squared_error(y_valid, y_valid_preds_ngrams[i]['y_valid_pred']), 3)\n",
    "    print(f'Validation score for model: {y_valid_preds_ngrams[i][\"model\"]} -- {sc}')\n",
    "for i in range(len(y_valid_preds_ngrams)):\n",
    "    vect = y_valid_preds_ngrams[i]['y_valid_pred'] * weights[i]\n",
    "    if i == 0:\n",
    "        y_valid_pred_ngram = vect\n",
    "    else:\n",
    "        y_valid_pred_ngram = y_valid_pred_ngram + vect\n",
    "sc = round(mean_squared_error(y_valid, y_valid_pred_ngram), 3)\n",
    "print(f'Weighted ensemble of models for validation set: {sc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, try this with iki info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for Ridge: 0.759, Best Params: {'alpha': 0.1, 'fit_intercept': False}\n",
      "Best Score for Ridge with Polynomial Features: 1.733, Best Params: {'alpha': 10, 'fit_intercept': False}\n",
      "Best Score for Lasso: 0.758, Best Params: {'alpha': 0, 'fit_intercept': False}\n",
      "Best Score for Lasso with Polynomial Features: 0.794, Best Params: {'alpha': 0.1, 'fit_intercept': True}\n",
      "Best Score for KNN: 0.763, Best Params: {'n_neighbors': 20}\n",
      "Best Score for SVR: 0.719, Best Params: {'C': 1, 'degree': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best Score for GBR: 0.719, Best Params: {'max_depth': 2, 'n_estimators': 100, 'subsample': 0.65}\n",
      "Best Score for LGBM: 0.719, Best Params: {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'num_leaves': 131072, 'subsample': 0.5}\n",
      "Best Score for XGB: 0.716, Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.5}\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 1s 8ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 10ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 7ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 1s 13ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "16/16 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan\n",
      "16/16 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "results_iki = run_tests(feature_dfs[2].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score for model: Ridge -- 0.525\n",
      "Validation score for model: Ridge with Polynomial Features -- 0.779\n",
      "Validation score for model: Lasso -- 0.533\n",
      "Validation score for model: Lasso with Polynomial Features -- 0.548\n",
      "Validation score for model: KNN -- 0.53\n",
      "Validation score for model: SVR -- 0.508\n",
      "Validation score for model: GBR -- 0.468\n",
      "Validation score for model: LGBM -- 0.486\n",
      "Validation score for model: XGB -- 0.469\n",
      "Weighted ensemble of models for validation set: 0.486\n"
     ]
    }
   ],
   "source": [
    "changable_rs = 0\n",
    "X, y = combined_feats, train_scores['score']\n",
    "X, X_valid, y, y_valid = train_test_split(X, y, test_size=.2, random_state=changable_rs)\n",
    "\n",
    "y_valid_preds_iki = []\n",
    "for model in models:\n",
    "    tuned_model = results_iki[model['name']]['model']\n",
    "    y_pred = tuned_model.predict(model['preprocess'](X_valid[feature_dfs[2].columns]))\n",
    "    y_valid_preds_iki.append({\n",
    "        'model': model['name'], \n",
    "        'features': 'iki', \n",
    "        'y_valid_pred': y_pred if model['name'] != 'NN' else y_pred[:,0], \n",
    "        'score': mean_squared_error(y_pred, y_valid)})\n",
    "\n",
    "weights = [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "y_valid_pred_iki = []\n",
    "for i in range(len(y_valid_preds_iki)):\n",
    "    sc = round(mean_squared_error(y_valid, y_valid_preds_iki[i]['y_valid_pred']), 3)\n",
    "    print(f'Validation score for model: {y_valid_preds_iki[i][\"model\"]} -- {sc}')\n",
    "for i in range(len(y_valid_preds_iki)):\n",
    "    vect = y_valid_preds_iki[i]['y_valid_pred'] * weights[i]\n",
    "    if i == 0:\n",
    "        y_valid_pred_iki = vect\n",
    "    else:\n",
    "        y_valid_pred_iki = y_valid_pred_iki + vect\n",
    "sc = round(mean_squared_error(y_valid, y_valid_pred_iki), 3)\n",
    "print(f'Weighted ensemble of models for validation set: {sc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the step for the aggregate info feature df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for Ridge: 0.667, Best Params: {'alpha': 0, 'fit_intercept': True}\n",
      "Best Score for Ridge with Polynomial Features: 1.687, Best Params: {'alpha': 10, 'fit_intercept': False}\n",
      "Best Score for Lasso: 0.679, Best Params: {'alpha': 0, 'fit_intercept': True}\n",
      "Best Score for Lasso with Polynomial Features: 0.775, Best Params: {'alpha': 0.1, 'fit_intercept': True}\n",
      "Best Score for KNN: 0.705, Best Params: {'n_neighbors': 20}\n",
      "Best Score for SVR: 0.666, Best Params: {'C': 1, 'degree': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best Score for GBR: 0.641, Best Params: {'max_depth': 3, 'n_estimators': 50, 'subsample': 0.9}\n",
      "Best Score for LGBM: 0.645, Best Params: {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'num_leaves': 131072, 'subsample': 0.5}\n",
      "Best Score for XGB: 0.641, Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.9}\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 1s 9ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 7ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 9ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 11ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 0s 8ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "16/16 [==============================] - 0s 3ms/step - loss: nan - root_mean_squared_error: nan\n",
      "16/16 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "results_agg = run_tests(feature_dfs[3].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score for model: Ridge -- 0.392\n",
      "Validation score for model: Ridge with Polynomial Features -- 1.396\n",
      "Validation score for model: Lasso -- 0.412\n",
      "Validation score for model: Lasso with Polynomial Features -- 0.461\n",
      "Validation score for model: KNN -- 0.415\n",
      "Validation score for model: SVR -- 0.388\n",
      "Validation score for model: GBR -- 0.411\n",
      "Validation score for model: LGBM -- 0.418\n",
      "Validation score for model: XGB -- 0.408\n",
      "Weighted ensemble of models for validation set: 0.378\n"
     ]
    }
   ],
   "source": [
    "changable_rs = 0\n",
    "X, y = combined_feats, train_scores['score']\n",
    "X, X_valid, y, y_valid = train_test_split(X, y, test_size=.2, random_state=changable_rs)\n",
    "\n",
    "y_valid_preds_agg = []\n",
    "for model in models:\n",
    "    tuned_model = results_agg[model['name']]['model']\n",
    "    y_pred = tuned_model.predict(model['preprocess'](X_valid[feature_dfs[3].columns]))\n",
    "    y_valid_preds_agg.append({\n",
    "        'model': model['name'], \n",
    "        'features': 'agg', \n",
    "        'y_valid_pred': y_pred if model['name'] != 'NN' else y_pred[:,0], \n",
    "        'score': mean_squared_error(y_pred, y_valid)})\n",
    "\n",
    "weights = [0.5, 0, 0, 0, 0, 0, .5, 0, 0]\n",
    "y_valid_pred_agg = []\n",
    "for i in range(len(y_valid_preds_agg)):\n",
    "    sc = round(mean_squared_error(y_valid, y_valid_preds_agg[i]['y_valid_pred']), 3)\n",
    "    print(f'Validation score for model: {y_valid_preds_agg[i][\"model\"]} -- {sc}')\n",
    "for i in range(len(y_valid_preds_agg)):\n",
    "    vect = y_valid_preds_agg[i]['y_valid_pred'] * weights[i]\n",
    "    if i == 0:\n",
    "        y_valid_pred_agg = vect\n",
    "    else:\n",
    "        y_valid_pred_agg = y_valid_pred_agg + vect\n",
    "sc = round(mean_squared_error(y_valid, y_valid_pred_agg), 3)\n",
    "print(f'Weighted ensemble of models for validation set: {sc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, other count info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for Ridge: 0.875, Best Params: {'alpha': 0, 'fit_intercept': True}\n",
      "Best Score for Ridge with Polynomial Features: 0.966, Best Params: {'alpha': 10, 'fit_intercept': False}\n",
      "Best Score for Lasso: 0.875, Best Params: {'alpha': 0, 'fit_intercept': True}\n",
      "Best Score for Lasso with Polynomial Features: 0.84, Best Params: {'alpha': 0.01, 'fit_intercept': False}\n",
      "Best Score for KNN: 0.865, Best Params: {'n_neighbors': 20}\n",
      "Best Score for SVR: 0.815, Best Params: {'C': 1, 'degree': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best Score for GBR: 0.761, Best Params: {'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Best Score for LGBM: 0.762, Best Params: {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'num_leaves': 131072, 'subsample': 0.5}\n",
      "Best Score for XGB: 0.759, Best Params: {'learning_rate': 0.03, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.65}\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 1s 9ms/step - loss: 3.8100 - root_mean_squared_error: 1.9519 - val_loss: 1.0917 - val_root_mean_squared_error: 1.0449\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0912 - root_mean_squared_error: 1.0446 - val_loss: 1.0496 - val_root_mean_squared_error: 1.0245\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0917 - root_mean_squared_error: 1.0449 - val_loss: 1.0318 - val_root_mean_squared_error: 1.0158\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0874 - root_mean_squared_error: 1.0428 - val_loss: 1.0129 - val_root_mean_squared_error: 1.0064\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0919 - root_mean_squared_error: 1.0449 - val_loss: 1.0177 - val_root_mean_squared_error: 1.0088\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0826 - root_mean_squared_error: 1.0405 - val_loss: 1.1430 - val_root_mean_squared_error: 1.0691\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0941 - root_mean_squared_error: 1.0460 - val_loss: 1.0442 - val_root_mean_squared_error: 1.0219\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0881 - root_mean_squared_error: 1.0431 - val_loss: 1.0702 - val_root_mean_squared_error: 1.0345\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0869 - root_mean_squared_error: 1.0425 - val_loss: 1.0306 - val_root_mean_squared_error: 1.0152\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0861 - root_mean_squared_error: 1.0422 - val_loss: 1.1325 - val_root_mean_squared_error: 1.0642\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.0829 - root_mean_squared_error: 1.0406 - val_loss: 1.0046 - val_root_mean_squared_error: 1.0023\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0809 - root_mean_squared_error: 1.0397 - val_loss: 1.0542 - val_root_mean_squared_error: 1.0268\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.0788 - root_mean_squared_error: 1.0387 - val_loss: 0.9999 - val_root_mean_squared_error: 0.9999\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0770 - root_mean_squared_error: 1.0378 - val_loss: 1.0004 - val_root_mean_squared_error: 1.0002\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0755 - root_mean_squared_error: 1.0371 - val_loss: 0.9969 - val_root_mean_squared_error: 0.9984\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0772 - root_mean_squared_error: 1.0379 - val_loss: 1.0794 - val_root_mean_squared_error: 1.0389\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0783 - root_mean_squared_error: 1.0384 - val_loss: 0.9931 - val_root_mean_squared_error: 0.9966\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.0749 - root_mean_squared_error: 1.0368 - val_loss: 0.9977 - val_root_mean_squared_error: 0.9988\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0753 - root_mean_squared_error: 1.0370 - val_loss: 1.0090 - val_root_mean_squared_error: 1.0045\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0724 - root_mean_squared_error: 1.0356 - val_loss: 1.1880 - val_root_mean_squared_error: 1.0899\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0778 - root_mean_squared_error: 1.0381 - val_loss: 1.1196 - val_root_mean_squared_error: 1.0581\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0642 - root_mean_squared_error: 1.0316 - val_loss: 0.9878 - val_root_mean_squared_error: 0.9939\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0692 - root_mean_squared_error: 1.0340 - val_loss: 0.9856 - val_root_mean_squared_error: 0.9928\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0749 - root_mean_squared_error: 1.0368 - val_loss: 0.9840 - val_root_mean_squared_error: 0.9920\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0645 - root_mean_squared_error: 1.0317 - val_loss: 0.9833 - val_root_mean_squared_error: 0.9916\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0683 - root_mean_squared_error: 1.0336 - val_loss: 0.9810 - val_root_mean_squared_error: 0.9905\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0665 - root_mean_squared_error: 1.0327 - val_loss: 0.9860 - val_root_mean_squared_error: 0.9930\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0662 - root_mean_squared_error: 1.0326 - val_loss: 1.0268 - val_root_mean_squared_error: 1.0133\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0697 - root_mean_squared_error: 1.0343 - val_loss: 0.9937 - val_root_mean_squared_error: 0.9968\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0565 - root_mean_squared_error: 1.0279 - val_loss: 0.9824 - val_root_mean_squared_error: 0.9912\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9824 - root_mean_squared_error: 0.9912\n",
      "16/16 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "results_other = run_tests(feature_dfs[4].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step\n",
      "Validation score for model: Ridge -- 1.038\n",
      "Validation score for model: Ridge with Polynomial Features -- 2.176\n",
      "Validation score for model: Lasso -- 1.038\n",
      "Validation score for model: Lasso with Polynomial Features -- 0.787\n",
      "Validation score for model: KNN -- 0.691\n",
      "Validation score for model: SVR -- 0.636\n",
      "Validation score for model: GBR -- 0.571\n",
      "Validation score for model: LGBM -- 0.588\n",
      "Validation score for model: XGB -- 0.567\n",
      "Validation score for model: NN -- 0.939\n",
      "Weighted ensemble of models for validation set: 0.564\n"
     ]
    }
   ],
   "source": [
    "changable_rs = 0\n",
    "X, y = combined_feats, train_scores['score']\n",
    "X, X_valid, y, y_valid = train_test_split(X, y, test_size=.2, random_state=changable_rs)\n",
    "\n",
    "y_valid_preds_other = []\n",
    "for model in models + [{'name': 'NN', 'preprocess': lambda X: X}]:\n",
    "    tuned_model = results_other[model['name']]['model']\n",
    "    y_pred = tuned_model.predict(model['preprocess'](X_valid[feature_dfs[4].columns]))\n",
    "    y_valid_preds_other.append({\n",
    "        'model': model['name'], \n",
    "        'features': 'other count info', \n",
    "        'y_valid_pred': y_pred if model['name'] != 'NN' else y_pred[:,0], \n",
    "        'score': mean_squared_error(y_pred, y_valid)})\n",
    "\n",
    "weights = [0, 0, 0, 0, 0, 0, .5, 0, .5, 0]\n",
    "y_valid_pred_other = []\n",
    "for i in range(len(y_valid_preds_other)):\n",
    "    sc = round(mean_squared_error(y_valid, y_valid_preds_other[i]['y_valid_pred']), 3)\n",
    "    print(f'Validation score for model: {y_valid_preds_other[i][\"model\"]} -- {sc}')\n",
    "for i in range(len(y_valid_preds_other)):\n",
    "    vect = y_valid_preds_other[i]['y_valid_pred'] * weights[i]\n",
    "    if i == 0:\n",
    "        y_valid_pred_other = vect\n",
    "    else:\n",
    "        y_valid_pred_other = y_valid_pred_other + vect\n",
    "sc = round(mean_squared_error(y_valid, y_valid_pred_other), 3)\n",
    "print(f'Weighted ensemble of models for validation set: {sc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run tests for gap info df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for Ridge: 0.722, Best Params: {'alpha': 10, 'fit_intercept': True}\n",
      "Best Score for Ridge with Polynomial Features: 1.201, Best Params: {'alpha': 10, 'fit_intercept': True}\n",
      "Best Score for Lasso: 0.718, Best Params: {'alpha': 0.01, 'fit_intercept': True}\n",
      "Best Score for Lasso with Polynomial Features: 0.704, Best Params: {'alpha': 0.01, 'fit_intercept': True}\n",
      "Best Score for KNN: 0.712, Best Params: {'n_neighbors': 20}\n",
      "Best Score for SVR: 0.69, Best Params: {'C': 1, 'degree': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best Score for GBR: 0.673, Best Params: {'max_depth': 3, 'n_estimators': 50, 'subsample': 0.65}\n",
      "Best Score for LGBM: 0.672, Best Params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'num_leaves': 131072, 'subsample': 0.5}\n",
      "Best Score for XGB: 0.668, Best Params: {'learning_rate': 0.03, 'max_depth': 2, 'n_estimators': 200, 'subsample': 0.5}\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 1s 8ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "16/16 [==============================] - 0s 3ms/step - loss: nan - root_mean_squared_error: nan\n",
      "16/16 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "results_gap = run_tests(feature_dfs[5].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score for model: Ridge -- 0.468\n",
      "Validation score for model: Ridge with Polynomial Features -- 0.752\n",
      "Validation score for model: Lasso -- 0.469\n",
      "Validation score for model: Lasso with Polynomial Features -- 0.468\n",
      "Validation score for model: KNN -- 0.479\n",
      "Validation score for model: SVR -- 0.455\n",
      "Validation score for model: GBR -- 0.414\n",
      "Validation score for model: LGBM -- 0.425\n",
      "Validation score for model: XGB -- 0.411\n",
      "Weighted ensemble of models for validation set: 0.411\n"
     ]
    }
   ],
   "source": [
    "changable_rs = 0\n",
    "X, y = combined_feats, train_scores['score']\n",
    "X, X_valid, y, y_valid = train_test_split(X, y, test_size=.2, random_state=changable_rs)\n",
    "\n",
    "y_valid_preds_gap = []\n",
    "for model in models:\n",
    "    tuned_model = results_gap[model['name']]['model']\n",
    "    y_pred = tuned_model.predict(model['preprocess'](X_valid[feature_dfs[5].columns]))\n",
    "    y_valid_preds_gap.append({\n",
    "        'model': model['name'], \n",
    "        'features': 'other count info', \n",
    "        'y_valid_pred': y_pred if model['name'] != 'NN' else y_pred[:,0], \n",
    "        'score': mean_squared_error(y_pred, y_valid)})\n",
    "\n",
    "weights = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "y_valid_pred_gap = []\n",
    "for i in range(len(y_valid_preds_gap)):\n",
    "    sc = round(mean_squared_error(y_valid, y_valid_preds_gap[i]['y_valid_pred']), 3)\n",
    "    print(f'Validation score for model: {y_valid_preds_gap[i][\"model\"]} -- {sc}')\n",
    "for i in range(len(y_valid_preds_gap)):\n",
    "    vect = y_valid_preds_gap[i]['y_valid_pred'] * weights[i]\n",
    "    if i == 0:\n",
    "        y_valid_pred_gap = vect\n",
    "    else:\n",
    "        y_valid_pred_gap = y_valid_pred_gap + vect\n",
    "sc = round(mean_squared_error(y_valid, y_valid_pred_gap), 3)\n",
    "print(f'Weighted ensemble of models for validation set: {sc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
